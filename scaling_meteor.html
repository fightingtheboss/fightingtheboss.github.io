<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Scaling Meteor by fightingtheboss</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Scaling Meteor</h1>
        <p>My experiences scaling Pegleg (pegleg.it), a Meteor project, beyond a single instance</p>


        <p class="view"><a href="https://github.com/fightingtheboss">View My GitHub Profile</a></p>

      </header>
      <section>
        <h3>
<a name="its-good-to-have-goals" class="anchor" href="#its-good-to-have-goals"><span class="octicon octicon-link"></span></a>It's Good To Have Goals</h3>

<p>I had three main objectives when scaling Pegleg to multiple instances:</p>

<ol>
<li>Site handles the load and works correctly</li>
<li>Simple deployment</li>
<li>Low cost</li>
</ol><p>I used these three criteria to evaluate the suitability of each solution for my purposes. Because of a lack of tools and time, I didn't load test any of these scenarios scientifically, so the decision on criteria 1 was made anecdotally (suitable enough for a small side-project like Pegleg). I'll circle back to load testing near the end.</p>

<h3>
<a name="back-to-the-future-aka-tldr" class="anchor" href="#back-to-the-future-aka-tldr"><span class="octicon octicon-link"></span></a>Back to the Future (aka TL;DR)</h3>

<p>Going from zero to hero took a few iterations (and a lot of research and trial-and-error). I ended up with three different deployment strategies for scaling Meteor:</p>

<ol>
<li>Manual deployment to AWS</li>
<li>AWS Elastic Beanstalk deployment</li>
<li>Custom deployment on private VPS</li>
</ol><p>After running on the manual AWS setup for a month, I ultimately ended up going with the private VPS option for simplicity and cost reasons that I'll get into below.</p>

<h3>
<a name="understanding-the-problem" class="anchor" href="#understanding-the-problem"><span class="octicon octicon-link"></span></a>Understanding The Problem</h3>

<p>The free hosting provided by Meteor at meteor.com is great for deploying prototypes and toys but if your traffic starts to ramp up, you'll eventually have to move on to your own infrastructure. Given that deploying to meteor.com is basically a black box, there's some background information you need to deploy a Meteor app to your own stack:</p>

<h4>
<a name="node" class="anchor" href="#node"><span class="octicon octicon-link"></span></a>Node</h4>

<p>As of Meteor 0.6.3.1, the current compatible version of node is <strong>0.8.x</strong>, so this is what you'll need to install on your server(s).</p>

<ul>
<li>The Meteor team is working on making Meteor compatible with the 0.10.x version of Node. There's a mention <a href="https://github.com/meteor/meteor/issues/859">here</a> and you can take a look at the code on the <a href="https://github.com/meteor/meteor/tree/node-0.10">node-0.10 branch</a>.</li>
<li>
<a href="https://launchpad.net/%7Echris-lea/+archive/node.js-legacy">Chris Lea maintains a legacy PPA</a> for installing the 0.8.x version of Node using apt-get</li>
</ul><h4>
<a name="mongodb" class="anchor" href="#mongodb"><span class="octicon octicon-link"></span></a>MongoDB</h4>

<h5>
<a name="backing-up-your-data" class="anchor" href="#backing-up-your-data"><span class="octicon octicon-link"></span></a>Backing up your data</h5>

<p>You'll need to back up the data from the DB on your meteor.com site</p>

<ul>
<li>Oli Evans made a dead simple bash script to help you called <a href="https://gist.github.com/olizilla/5209369">Meteor Dump</a>
</li>
</ul><h5>
<a name="hosting-your-data" class="anchor" href="#hosting-your-data"><span class="octicon octicon-link"></span></a>Hosting your data</h5>

<p>Meteor uses <a href="http://www.mongohq.com">MongoHQ</a> and unless you have some special reason to run your own MongoDB server, I highly recommend doing the same. The sandbox account gives you 512MB of storage for free and the prices are reasonable beyond that.</p>

<ul>
<li>It's super simple to <a href="https://groups.google.com/d/msg/meteor-talk/KvDWrqZpy-w/5-xrKOjHVFkJ">copy your data directly across to your new MongoHQ database</a> once you've created an account</li>
</ul><h4>
<a name="meteor-and-meteorite" class="anchor" href="#meteor-and-meteorite"><span class="octicon octicon-link"></span></a>Meteor (and Meteorite)</h4>

<h5>
<a name="bundling-your-app" class="anchor" href="#bundling-your-app"><span class="octicon octicon-link"></span></a>Bundling your app</h5>

<p>You'll need to bundle your app either before or during deploy using <code>meteor bundle</code> (or <code>mrt bundle</code>)</p>

<ul>
<li>This creates a node-friendly bundle that you can run with node directly (i.e. <code>node bundle/main.js</code>)</li>
<li>If you create your bundle locally and then upload to your server, you'll have to be careful to rebuild your node dependencies in the server environment, <a href="http://docs.meteor.com/#deploying">as noted in the Meteor docs in the red text under <em>Running your own infrastructure</em></a>
</li>
</ul><h5>
<a name="packages" class="anchor" href="#packages"><span class="octicon octicon-link"></span></a>Packages</h5>

<p>If you add packages using Meteorite locally then you'll want Meteorite on the server as well</p>

<ul>
<li>This is bound to change pretty soon as Meteor (as of 0.6.0) now handles its own versioning and codifies package management a bit more and <a href="https://groups.google.com/forum/?fromgroups#!topic/meteor-talk/1RwTlcH0Wzg">Meteorite is soon to change to catch up</a>.</li>
</ul><h5>
<a name="environment-variables" class="anchor" href="#environment-variables"><span class="octicon octicon-link"></span></a>Environment Variables</h5>

<p>Meteor expects certain environment variables are set when the app is started:      </p>

<p><code>MONGO_URL</code><br>
The URL to your MongoDB instance using the mongodb:// protocol.</p>

<p><code>ROOT_URL</code><br>
If you serve your site from a domain other than localhost, you'll need to set this so that URLs within your app point to the right place (<a href="http://docs.meteor.com/#meteor_absoluteurl">Meteor.absoluteUrl</a> depends on this variable being set).</p>

<p><code>PORT</code><br>
The port the app server should run on. This will vary depending on your environment and setup as we'll discuss below.</p>

<p>Other packages may require specific environment variables (e.g. MAIL_URL).</p>

<h4>
<a name="load-balancing--session-affinity" class="anchor" href="#load-balancing--session-affinity"><span class="octicon octicon-link"></span></a>Load Balancing &amp; Session Affinity</h4>

<p>When you're running more than one instance of your app, you'll need to spread the requests across them using a load balancer.</p>

<ul>
<li>Because of the way Meteor works, you'll need a load balancer that supports "session affinity" or "sticky sessions". <a href="http://stackoverflow.com/a/13716069/2202261">Read Matt DeBergalis' succinct explanation.</a>
</li>
<li>A secondary problem related to load balancing is that there will be a delay when updating clients connected to instances other than the one where writes were made (this is explained by Matt DeBergalis in the above link as well). <a href="https://github.com/arunoda/meteor-cluster">Meteor Cluster</a> is an elegant workaround using Redis if that is a deal-breaker for your app. In the longer term, <a href="https://trello.com/card/multitier-server-architecture-support-very-large-numbers-of-simultaneous-clients/508721606e02bb9d570016ae/46">this will be addressed in future versions of Meteor</a>.</li>
</ul><p>Some of the above is covered in the Meteor docs under <a href="http://docs.meteor.com/#deploying">"Running on your own infrastructure"</a>, which is a good thing to read before continuing.</p>

<h3>
<a name="manual-deploy-to-aws" class="anchor" href="#manual-deploy-to-aws"><span class="octicon octicon-link"></span></a>Manual Deploy to AWS</h3>

<p>After reading the docs and a lot of articles on using AWS, I set up an EC2 AMI with Node, NPM, Meteor and <a href="https://github.com/nodejitsu/forever">Forever</a> installed on it (available publically as <code>ami-d4f196bd</code>). Then I went through the ordeal of installing the AWS EC2 Tools locally on my machine, which isn't fun since <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/SettingUp_CommandLine.html">the documentation isn't the greatest</a> (It's doable, just not fun, I'm going to avoid going on that tangent because it's a post unto itself). Finally I spun up a few instances of my AMI, hooked up the Load Balancer and was ready to deploy. For notes on deploying to AWS with a Load Balancer, check out <a href="http://www.ripariandata.com/blog/creating-an-aws-elastic-load-balancer">this blog post about load balancing on AWS</a>.</p>

<p>I started off with <a href="https://github.com/netmute/meteor.sh">Meteor.sh</a> and modified it to handle multiple instances. Again, this requires installing the AWS API Tools. You can find the modified script in the following fork: </p>

<p><a href="https://github.com/fightingtheboss/meteor.sh">Meteor.sh fork with support for multiple EC2 instances</a></p>

<p>Since the bash script ran the deploy in sequence rather than in parallel, it quickly became unacceptably long to deploy to many instances. I needed a parallelized and easily customizable deploy process so I turned to the tool I have the most experience with: <a href="http://capistranorb.com/">Capistrano</a>.</p>

<p>Capistrano is a Ruby-based deploy tool that is generally used with Rails. It parallelizes deploys to multiple servers and gives you complex control over how the deploy is performed and what you can do both locally and on the server. Another added benefit of this type of deployment is that it's deployed straight from your Git repo, cloned right on the target server, so there are no files to copy and you'll never be unsure of which version is in production. Obviously this means you need to keep your code in Git and the repo has to be accessible at the server, but that's a pretty basic requirement for any development these days. You'll also need to install the <a href="https://github.com/leehambley/railsless-deploy/">railsless-deploy gem</a> and add a <code>require railsless-deploy</code> to your Capfile.</p>

<p>You can find the deploy script I created to do this in the following Gist:
<a href="https://gist.github.com/fightingtheboss/5842941">Capistrano AWS EC2 manual deploy script</a></p>

<p>This actually worked pretty well. In my app, I added a <code>/ping</code> endpoint to my router that responded with <code>200 OK</code> to act as the health check endpoint for the Load Balancer using the <a href="https://github.com/tmeasday/meteor-router">Router</a> package, like this:</p>

<div class="highlight"><pre><span class="nx">Meteor</span><span class="p">.</span><span class="nx">Router</span><span class="p">.</span><span class="nx">add</span><span class="p">(</span><span class="s1">'/ping'</span><span class="p">,</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="s2">"OK"</span><span class="p">]);</span>
</pre></div>

<p>This was a decent solution but had some points against it:</p>

<ol>
<li>Trying to deploy Meteor (or any Node apps) to Micro instances is doable but not that reliable. Because of the way Micro instances work, they'll give you short bursts of power but then they'll be throttled back down to pretty much nothing, making that instance pretty much unresponsive for a while.</li>
<li>Going above the Micro level starts to cost a lot more money, so it's up to you whether you're willing to spend the money. Ultimately, I ended up spinning up 9 Micro instances that were running above 50% capacity for a month just to see what would happen since I was on the "free tier" (and because I'm stubborn) and it cost me $160. I may have been better off using a couple of Small instances instead, but overall the cost was way too high for this to be the end of the story for me. </li>
</ol><h3>
<a name="aws-elastic-beanstalk-deployment" class="anchor" href="#aws-elastic-beanstalk-deployment"><span class="octicon octicon-link"></span></a>AWS Elastic Beanstalk Deployment</h3>

<p>During my research into my manual AWS deploy setup I kept coming across mentions of Elastic Beanstalk. Because I was in the thick of trying to figure out basics about AWS and EC2 I only took a cursory look into it until I had everything up and running. Once that first stab was working, I realised that with the Micro instances I would need a way of auto-scaling the number of instances when load went up and down to save cost, and for each new instance I would need to deploy. Turns out that's <em>exactly what Elastic Beanstalk is for</em>. AWS had recently released <a href="http://aws.amazon.com/about-aws/whats-new/2013/03/11/announcing-aws-elastic-beanstalk-for-node-js/">Elastic Beanstalk for Node.js</a> so the stars were aligned.</p>

<p>EB is intended to set up everything you need for a production application: instances, load balancer, monitoring, and auto-scaling, all configurable through their web interface. It's got its <a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/usingCLI.html">own set of AWS Tools</a> that need to be installed (just as annoying as the EC2 Tools, but now I had experience). These tools hook into Git and allow you to deploy with one command on the command-line once they're all setup:</p>

<div class="highlight"><pre>git aws.push
</pre></div>

<p>It's a bit more complicated than that, though. To get your Meteor app up and running properly for each new instance requires a configuration file that you have to store in the <code>/.ebextensions</code> subdir of your application. After parsing through the configuration docs and probably 50+ trial deploys, I finally got everything up and running with a green health check and a running app.</p>

<p>To save you some of the trouble, I've created a Gist with the working deploy script, which not only sets up Meteor and Meteorite, but does some custom tweaking to the built-in nginx server that serves static assets:</p>

<p><a href="https://gist.github.com/fightingtheboss/5432059">EB Configuration File</a></p>

<p>This option had potential but I didn't spend a lot of time with it once I got it working. It still depends on expensive EC2 instances and my mind was already on the next possible solution by the morning after I got this working.</p>

<h3>
<a name="custom-deployment-on-private-vps" class="anchor" href="#custom-deployment-on-private-vps"><span class="octicon octicon-link"></span></a>Custom Deployment on Private VPS</h3>

<p>A few people suggested checking out DigitalOcean and I even got a great $200 promo code to use so I decided to give them a try. The thinking was that one really beefy server could probably run several instances of a Meteor app and handle the load as well or better than many small ones. At the very least it wouldn't be as variable as trying to rely on AWS Micro instances and at $20/month, the cost was potentially way more manageable.</p>

<p>The setup I decided to pursue was nginx (for serving static assets) in front of both HAProxy (which can provide session affinity) and node/Meteor. Rather than distributing the load across server instances, I would be distributing the load across multiple app instances running on different ports on the same machine. This would all be deployed with Capistrano, with some slight tweaks to the script I used earlier for AWS.</p>

<p>So I setup my new droplet with the bare minimum to run a Meteor project: Node, NPM, Meteor, Meteorite, Forever (just as on EC2, but now I was a stone-cold expert). Then I added nginx and HAProxy and tweaked their configurations to serve the static assets from nginx and the app data from the load-balanced app servers. You can take a look at my configuration files here:</p>

<ol>
<li><a href="https://gist.github.com/fightingtheboss/5843323">Nginx configuration</a></li>
<li><a href="https://gist.github.com/fightingtheboss/5843330">HAProxy configuration</a></li>
<li><a href="https://gist.github.com/fightingtheboss/5843349">Capistrano deploy script</a></li>
</ol><p>I've been running this setup for a couple of months now with 3 app instances behind the load balancer and haven't had a single moment of downtime or slowness. Once everything is committed and pushed to my git repo deploy is dead simple, all it takes is:</p>

<div class="highlight"><pre>cap deploy -s <span class="nv">instances</span><span class="o">=</span>3
</pre></div>

<p>The only possible annoyance is if I want to run more instances on the same server I'll need to update my HAProxy configuration, which I could actually do via the deploy script with a little <code>sed</code> magic, but for now it's not a problem I have.</p>

<p>There are many benefits to this setup:</p>

<ol>
<li>It's much, much cheaper than AWS ($20/month)</li>
<li>It's way more reliable and requires fewer instances for the same load (anecdotally)</li>
<li>Server setup is a one-time operation since all of the app instances are running on the same machine</li>
<li>You can clone images to new machines as things grow (DigitalOcean calls them 'droplets')</li>
</ol><h3>
<a name="load-testing--conclusion" class="anchor" href="#load-testing--conclusion"><span class="octicon octicon-link"></span></a>Load Testing &amp; Conclusion</h3>

<p>This is a topic I don't know much about and from what I've read in the meteor-talk group, it's not a trivial task to figure out with Meteor applications. This whole thing would definitely be more scientific with some load numbers to back it up, but for a small app like mine, anecdotal results are good enough for me. In the final result, the app works great with minimal latency and no unexpected behaviour at all, so I'm happy. It would be interesting to hear results from others who have done some load testing against Meteor apps / Node apps in general to perhaps improve performance based on their findings.</p>

<hr><h3>
<a name="background-for-those-interested" class="anchor" href="#background-for-those-interested"><span class="octicon octicon-link"></span></a>Background (for those interested)</h3>

<h4>
<a name="beginnings" class="anchor" href="#beginnings"><span class="octicon octicon-link"></span></a>Beginnings</h4>

<p>I built <a href="http://pegleg.it">Pegleg</a> back in January as a side-project to learn Meteor and to help friends and film-buffs find full-length movies on YouTube by working together. Initially I was using the generously provided and dead simple free meteor.com hosting, which is the perfect platform for getting your Meteor prototypes some real-world users on the web. With a few blog posts about it and word of mouth, it slowly gained a bit of popularity.</p>

<h4>
<a name="blow-up" class="anchor" href="#blow-up"><span class="octicon octicon-link"></span></a>Blow-Up</h4>

<p>After being up and slowly improved for about six or eight weeks, the link to Pegleg was posted on Hacker News on a Friday morning and made it to the home page. After an initial bout of euphoria about having hit on the holy grail of an HN home page mention, I was quickly hit with the reality of what that means. The free hosting provided by Meteor wasn't designed to handle that kind of load and the site slowed to an unusable crawl.</p>

<h4>
<a name="short-circuit" class="anchor" href="#short-circuit"><span class="octicon octicon-link"></span></a>Short-Circuit</h4>

<p>After trying to resolve things with the gracious and patient help of Kara and David at Meteor one thing became certain: I needed to scale off of the Meteor free hosting to meet the needs of the new influx of users. This was easier said than done because there wasn't much in the way of documentation on that front. David pointed me to <a href="http://www.ripariandata.com/blog/creating-an-aws-elastic-load-balancer">this blog post about load balancing on AWS</a> to get me started and that's where we'll begin this journey.</p>

<h4>
<a name="batteries-not-included" class="anchor" href="#batteries-not-included"><span class="octicon octicon-link"></span></a>Batteries Not Included</h4>

<p>As a caveat, I'm certainly not a sys-ops master, and I often find jockeying servers and worrying about deployments to be a tedious necessary evil to get my sites online. This situation forced me to learn a bunch of the stuff I'd been wilfully ignoring for as long as I could. If you are great at this stuff I'd love to hear feedback on better ways to approach this.</p>
      </section>
      <footer>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-6017309-11");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>